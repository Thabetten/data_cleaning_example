{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13)\n",
      "(3587, 9)\n",
      "(23377, 12)\n"
     ]
    }
   ],
   "source": [
    "#Import libraries and data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#df_profiles_q1 is profile data to be analyzed as per question 1.\n",
    "df_profiles_q1 = pd.read_excel('Data_set1.xlsx', header = 0, dtype = 'object')\n",
    "#df_new_data_q2 is the data for purchase in question 2 of the assignment.\n",
    "df_new_data_q2 = pd.read_excel('DataSet7734_USA_Consumers_test-ver2.xls')\n",
    "#df_old data contains the old data already owned by piple for question 2 of the assignment.\n",
    "df_old_data_q2 = pd.read_excel('DataSet7734_USA_Consumers_test-ver2.xls', sheet_name = 'Current-07734ZipCode')\n",
    "\n",
    "#Print shapes to have a general idea of the data.\n",
    "\n",
    "print(df_profiles_q1.shape)\n",
    "print(df_new_data_q2.shape)\n",
    "print(df_old_data_q2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Domain  # of Users  Percent of Users\n",
      "0          gmail.com         139              2.78\n",
      "1            att.net         136              2.72\n",
      "2           live.com         135              2.70\n",
      "3             cs.com         133              2.66\n",
      "4          yahoo.com         126              2.52\n",
      "5        comcast.net         125              2.50\n",
      "6            aim.com         122              2.44\n",
      "7         qwerty.org         113              2.26\n",
      "8            aol.com         113              2.26\n",
      "9        outlook.com         113              2.26\n",
      "10     earthlink.net         113              2.26\n",
      "11     sbcglobal.net         111              2.22\n",
      "12           msn.com         111              2.22\n",
      "13  worldnet.att.net         109              2.18\n",
      "14       verizon.net         109              2.18\n",
      "15           cox.net         109              2.18\n",
      "16       gateway.com         107              2.14\n",
      "17          juno.com         105              2.10\n",
      "18         ymail.com         104              2.08\n",
      "19   hello-world.org         102              2.04\n",
      "20       hotmail.com         102              2.04\n",
      "21        icloud.com         101              2.02\n",
      "22        holder.com          99              1.98\n",
      "23       netzero.net          98              1.96\n",
      "24     bellsouth.net          96              1.92\n",
      "25       prodigy.net          95              1.90\n",
      "26      adelphia.net          94              1.88\n",
      "27      peoplepc.com          94              1.88\n",
      "28         attb1.com          93              1.86\n",
      "29          mail.com          92              1.84\n",
      "30         email.com          91              1.82\n",
      "31       netzero.com          90              1.80\n",
      "32         attbi.com          85              1.70\n",
      "33    roadrunner.com          85              1.70\n",
      "34         nj.rr.com          82              1.64\n",
      "35      netscape.com          82              1.64\n",
      "36     insightbb.com          81              1.62\n",
      "37    centurytel.net          81              1.62\n",
      "38           usa.net          81              1.62\n",
      "39        random.com          80              1.60\n",
      "40           gte.net          79              1.58\n",
      "41      netscape.net          78              1.56\n",
      "42    rocketmail.com          78              1.56\n",
      "43     wmconnect.com          77              1.54\n",
      "44        san.rr.com          76              1.52\n",
      "45      twcny.rr.com          74              1.48\n",
      "46     optonline.net          72              1.44\n",
      "47      mailcity.com          72              1.44\n",
      "48       charter.net          72              1.44\n",
      "49       example.org          64              1.28\n",
      "50       address.com          62              1.24\n",
      "51          test.edu          59              1.18\n"
     ]
    }
   ],
   "source": [
    "#Here we find the frequency of email domain used by creaing a seperate list of domains through splitting the string.\n",
    "#We make a dataframe out of the splits column.\n",
    "email =  df_profiles_q1.email.str.split(pat = '@', expand = True)\n",
    "\n",
    "#We get the frequency of each Value.\n",
    "d_count = email[1].value_counts()\n",
    "\n",
    "\n",
    "#Make a dataframe of this.\n",
    "counts_df = pd.DataFrame(d_count)\n",
    "\n",
    "\n",
    "#This will hold the percentage of use value for each domain.\n",
    "dom_per = []\n",
    "\n",
    "\n",
    "#This loop will ger the percentage and add it to dom_per.\n",
    "for i in counts_df[1]:\n",
    "    dom_per.append(i*100/sum(counts_df[1]))\n",
    "\n",
    "    \n",
    "#We add a column to the dataframe for percent of users per domain with dummy name.\n",
    "counts_df['Up'] = dom_per\n",
    "\n",
    "#We reindex the new dataframe.\n",
    "counts_df.reset_index(inplace = True)\n",
    "\n",
    "#Rename the columns.\n",
    "counts_df.columns = ['Domain', '# of Users', 'Percent of Users']\n",
    "\n",
    "print(counts_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 9)\n",
      "Number of people with N of mobile phones. \n",
      " 0    1686\n",
      "1    1717\n",
      "2     990\n",
      "3     432\n",
      "4     136\n",
      "5      32\n",
      "6       6\n",
      "7       1\n",
      "Name: # Mobiles, dtype: int64\n",
      "Number of people with N landlines. \n",
      " 0     339\n",
      "1    1240\n",
      "2     974\n",
      "3     802\n",
      "4     697\n",
      "5     501\n",
      "6     298\n",
      "7     129\n",
      "8      20\n",
      "Name: # Landlines, dtype: int64\n",
      "% of people with N mobile phones. \n",
      " 0    33.72\n",
      "1    34.34\n",
      "2    19.80\n",
      "3     8.64\n",
      "4     2.72\n",
      "5     0.64\n",
      "6     0.12\n",
      "7     0.02\n",
      "Name: # Mobiles, dtype: float64\n",
      "% of people with N landlines \n",
      " 0     6.78\n",
      "1    24.80\n",
      "2    19.48\n",
      "3    16.04\n",
      "4    13.94\n",
      "5    10.02\n",
      "6     5.96\n",
      "7     2.58\n",
      "8     0.40\n",
      "Name: # Landlines, dtype: float64\n",
      "email          b.williams@cox.net\n",
      "# Mobiles                       0\n",
      "# Landlines                     3\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Prefixes can easily be added as a fixed list or brought in as a data frame.\n",
    "#prefixes = ['20', '21', '22', '30', '31', '32', '40', '41', '42', '50', '51', '52', '60', '61', '62']\n",
    "\n",
    "df_prefixes = pd.read_excel('Data_set1.xlsx', header = 0, sheet_name = 'mobile prefixes', dtype = 'str')\n",
    "prefixes = list(df_prefixes['mobile prefixes'])\n",
    "\n",
    "num_list = []\n",
    "\n",
    "\n",
    "#Remove all unnecessary columns from the data frame for ease.\n",
    "df_profiles_q1_reduced = df_profiles_q1.drop(['index', 'first', 'last', 'gender'], axis = 1)\n",
    "\n",
    "\n",
    "#Check shape is as expected.\n",
    "print(df_profiles_q1_reduced.shape)\n",
    "\n",
    "\n",
    "#This loop creates a string of two digit numbers from 0 to 99 as might appear at the beginning of a phone number.\n",
    "for z in range(0, 99):\n",
    "    if z < 10:\n",
    "        num_list.append('0' + str(z))\n",
    "    else:\n",
    "        num_list.append(str(z))\n",
    "        \n",
    "#land pres is all combos of two digits not in mobile pregfixes.\n",
    "\n",
    "landpres = [x for x in num_list if x not in prefixes]\n",
    "\n",
    "phone_lines = []\n",
    "\n",
    "\n",
    "#This loop will iterate through the rows in the reduced profile data and will check if the first two digits are\n",
    "#for a landline or mobile phone and then count the number of each for the row.\n",
    "#The two elif statements are equivalent. \n",
    "for i in df_profiles_q1_reduced.itertuples(index = False):\n",
    "    mobile = 0\n",
    "    landline = 0\n",
    "    phones = []\n",
    "    for k in i[1:9]:\n",
    "        k = str(k)\n",
    "        if k[0:2] in prefixes:\n",
    "            mobile += 1\n",
    "        #elif k[0:2] in num_list and k[0:2] not in prefixes:\n",
    "        elif k[0:2] in landpres:\n",
    "            landline += 1\n",
    "    phones.append(i[0]), phones.append(mobile), phones.append(landline)\n",
    "    phone_lines.append(phones)\n",
    "\n",
    "\n",
    "\n",
    "df_phones = pd.DataFrame(phone_lines, columns = ['email', '# Mobiles', '# Landlines'])\n",
    "\n",
    "pd.to_numeric(df_phones['# Mobiles'])\n",
    "pd.to_numeric(df_phones['# Landlines'])\n",
    "\n",
    "more_than_one_phone = df_phones.loc[(df_phones['# Mobiles'] > 1) | (df_phones['# Landlines'] > 1)]\n",
    "                                          \n",
    "\n",
    "\n",
    "\n",
    "print('Number of people with N of mobile phones.', '\\n', df_phones['# Mobiles'].value_counts().sort_index())\n",
    "\n",
    "print('Number of people with N landlines.', '\\n', df_phones['# Landlines'].value_counts().sort_index())\n",
    "\n",
    "print('% of people with N mobile phones.', '\\n', (df_phones['# Mobiles'].value_counts().sort_index()/5000)*100)\n",
    "\n",
    "print('% of people with N landlines', '\\n', (df_phones['# Landlines'].value_counts().sort_index()/5000)*100)\n",
    "\n",
    "\n",
    "#Print a single entry to compare to a line in the original data (I did this in Excel).\n",
    "print(df_phones.iloc[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fill value by column of the old data. \n",
      " [('First name', 100.0), ('middle name', 21.833426017025282), ('last name', 100.0), ('gender', 65.01689694999358), ('house number', 98.60546691192198), ('street name', 99.45673097488985), ('city', 99.9871668734226), ('state', 100.0), ('zip', 100.0), ('country', 100.0), ('phone number', 68.27651110065449), ('email', 28.8788125080207)]\n",
      "\n",
      " The fill value by column of the new data. \n",
      " [('EMail', 100.0), ('F Name', 88.68134931697797), ('L Name', 98.43880680234179), ('Address', 95.00975745748536), ('City', 100.0), ('State', 100.0), ('Zip', 100.0), ('DOB', 100.0), ('Phone Number', 92.19403401170895)]\n",
      "\n",
      " The mean fill of the old data is \n",
      " 0    81.837918\n",
      "dtype: float64\n",
      "\n",
      " The mean fill of the new data is \n",
      " 0    97.147105\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#In this section we will calculate the fill values for columns in the old data for Kearney N.J. and the sample data for purchase.\n",
    "#We will do this by finding the ratio of values the are not NA to the total number of values.\n",
    "\n",
    "#Establish list of headers for convenience.\n",
    "\n",
    "raw_list_new_data = list(df_new_data_q2.columns.values)\n",
    "raw_list_old_data = list(df_old_data_q2.columns.values)\n",
    "\n",
    "#Create empty lists for fill ratios.\n",
    "\n",
    "fill_new = []\n",
    "fill_old = []\n",
    "comparison_old_new = []\n",
    "\n",
    "\n",
    "#The fill value is calculated by dropping NA values from each column and dividing by the original length of the column.\n",
    "#looking at the data in a spreadsheet reveals that some values are filled in phone numbers for the old data that should be NA.\n",
    "#I.E. some phone numbers as '0' in the old data.\n",
    "#This will be remedied buy replacing zeros with NA values.\n",
    "\n",
    "df_old_data_q2['phone number'].replace(0, np.nan, inplace = True)\n",
    "\n",
    "\n",
    "#This iterates of columns in the new data to get the fill percentage.\n",
    "\n",
    "\n",
    "for i in raw_list_new_data:\n",
    "    fill_new.append(len(df_new_data_q2[str(i)].dropna())*100/len(df_new_data_q2[str(i)]))\n",
    "\n",
    "#This creates a list pairing the column head with the fill percentage.\n",
    "fill_by_col_new = list(zip(raw_list_new_data, fill_new))\n",
    "\n",
    "#Do the same for the old data.\n",
    "\n",
    "for k in raw_list_old_data:\n",
    "    fill_old.append((len(df_old_data_q2[str(k)].dropna()))/len(df_old_data_q2[str(k)])*100)\n",
    "\n",
    "fill_by_col_old = list(zip(raw_list_old_data, fill_old))\n",
    "\n",
    "#Print both.\n",
    "print('The fill value by column of the old data.', '\\n', fill_by_col_old)\n",
    "print('\\n', 'The fill value by column of the new data.', '\\n', fill_by_col_new)\n",
    "\n",
    "#Make the lists into dataframes and get a mean fill value.\n",
    "\n",
    "fill_old_df = pd.DataFrame(fill_old)\n",
    "fill_new_df = pd.DataFrame(fill_new)\n",
    "\n",
    "print('\\n', 'The mean fill of the old data is', '\\n', fill_old_df.mean())\n",
    "\n",
    "print('\\n', 'The mean fill of the new data is', '\\n', fill_new_df.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            EMail   F Name      L Name             Address  \\\n",
      "1       CAROLHARTSGROVE@YAHOO.COM    CAROL  HARTSGROVE      573 PALMER AVE   \n",
      "2             JCROD0903@GMAIL.COM  MICHAEL   RODRIGUEZ          133 8TH ST   \n",
      "3                CHUCKASS@AOL.COM  CHARLIE      BOWMAN   7 SAINT PETERS PL   \n",
      "4          CHARLIEB@BELLSOUTH.NET  CHARLIE      BOWMAN  11 SAINT PETERS PL   \n",
      "5        ACOLLAZO1963@HOTMAIL.COM      KAJ    SCHALLER      26 JOHNSON TER   \n",
      "6               TTUCCILLE@MSN.COM  TABITHA    TUCCILLE        40B CARR AVE   \n",
      "7   BERYI.TRUJILLO@CENTURYTEL.NET    BERYI    TRUJILLO        298 CARR AVE   \n",
      "8                MZEBRO@GMAIL.COM   SIDNEY         TER       24 SIDNEY TER   \n",
      "9            CJARBECK@GATEWAY.NET  CARMELA     JARBECK           96 7TH ST   \n",
      "10            DAWN.MACKEY@AOL.COM     DAWN      MACKEY      27 BELLEZZA CT   \n",
      "11               ERICFABS@MSN.COM      NaN      FABIAN                 NaN   \n",
      "12         TOMHOPPESR@VERIZON.NET   THOMAS      THOMAS          46 MAIN ST   \n",
      "13              MIKEDEB21@AOL.COM   DEBBIE      DEANNA   56 WASHINGTON AVE   \n",
      "14               KDONNELL@TDS.NET     KATE    DONNELLY       43 N SHORE ST   \n",
      "15        JOAN.DONNELLY@YAHOO.COM     JOAN    DONNELLY    36 OCEANVIEW AVE   \n",
      "16               GCARFI@YAHOO.COM   GEORGE       CARFI        2 COTTAGE PL   \n",
      "17           ELITE16.WB@GMAIL.COM  WILLIAM       BROWN      12 LINCOLN AVE   \n",
      "18          RGISSUBEL@HOTMAIL.COM   RONALD    GISSUBEL   3 MORNINGSIDE AVE   \n",
      "19            WJLEIGH52@YAHOO.COM   JOSEPH       LEIGH        102 CARR AVE   \n",
      "20          JLIPSKI@EARTHLINK.NET   JOSEPH      LIPSKI  213 MAIN ST APT 15   \n",
      "21        KABOOM2463000@YAHOO.COM     JOSE     SANTANA           90 OAK ST   \n",
      "22        CHAINS140@AMERITECH.NET    FRANK   COLASURDO       78 LIBERTY PL   \n",
      "23          ACKERMAN@CORDLESS.COM  BARBARA    ACKERMAN      70 KENNEDY WAY   \n",
      "24          LADYBOLTON714@AOL.COM    DONNA       ZUMMO        35 WILLOW ST   \n",
      "\n",
      "               City State   Zip        DOB  Phone Number  \n",
      "1         KEANSBURG    NJ  7734 1976-01-02  7.324952e+08  \n",
      "2         KEANSBURG    NJ  7734 1976-01-03  7.329303e+09  \n",
      "3         KEANSBURG    NJ  7734 1976-01-04  7.324716e+09  \n",
      "4         KEANSBURG    NJ  7734 1976-01-05  6.015841e+09  \n",
      "5   HAZLET TOWNSHIP    NJ  7734 1976-01-06  4.258768e+09  \n",
      "6         KEANSBURG    NJ  7734 1976-01-07  7.326007e+09  \n",
      "7         KEANSBURG    NJ  7734 1976-01-08  7.326008e+09  \n",
      "8         KEANSBURG    NJ  7734 1976-01-09  7.324951e+09  \n",
      "9   HAZLET TOWNSHIP    NJ  7734 1976-01-10  7.326006e+09  \n",
      "10        KEANSBURG    NJ  7734 1976-01-11  7.325989e+09  \n",
      "11        KEANSBURG    NJ  7734 1976-01-12           NaN  \n",
      "12        KEANSBURG    NJ  7734 1976-01-13  7.324718e+09  \n",
      "13        KEANSBURG    NJ  7734 1976-01-14  7.323070e+09  \n",
      "14        KEANSBURG    NJ  7734 1976-01-15  7.325987e+09  \n",
      "15        KEANSBURG    NJ  7734 1976-01-16  7.328619e+09  \n",
      "16        KEANSBURG    NJ  7734 1976-01-17  7.324956e+09  \n",
      "17        KEANSBURG    NJ  7734 1976-01-18  7.324711e+09  \n",
      "18        KEANSBURG    NJ  7734 1976-01-19  7.324951e+09  \n",
      "19        KEANSBURG    NJ  7734 1976-01-20  7.326975e+09  \n",
      "20        KEANSBURG    NJ  7734 1976-01-21  7.326006e+09  \n",
      "21        KEANSBURG    NJ  7734 1976-01-22  7.324711e+09  \n",
      "22  HAZLET TOWNSHIP    NJ  7734 1976-01-23  7.325988e+09  \n",
      "23        KEANSBURG    NJ  7734 1976-01-24  7.327874e+09  \n",
      "24        KEANSBURG    NJ  7734 1976-01-25  2.787522e+07  \n"
     ]
    }
   ],
   "source": [
    "#While the new data seems to have a better fill than the old data, it still may not be of high quality.\n",
    "\n",
    "\n",
    "print(df_new_data_q2.iloc[1:25])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3587, 9)\n",
      "AKERHOUSE1@YAHOO.COM              1302\n",
      "A.HILL@GO.COM                        6\n",
      "FRANK@WORLDNET.ATT.NET               3\n",
      "SOCIALWORKJ@YAHOO.COM                3\n",
      "IMTHECHENNMBR2@FRONTIERNET.NET       3\n",
      "Name: EMail, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#First a sample of the data is inpspected. It is immediately obvious two phone numbers are of the wrong length.\n",
    "#It is also immediately obvious that data seems sorted by both birthdate and alphabetically by name.\n",
    "#In addition the first two 'Chalie Bowman' born a day appart live on the same street.\n",
    "#This seems suspicious. \n",
    "\n",
    "#Next we find the dimensions of the data.\n",
    "print(df_new_data_q2.shape)\n",
    "\n",
    "\n",
    "dupes = df_new_data_q2['EMail'].value_counts()\n",
    "\n",
    "print(dupes[0:5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2203, 9)\n",
      "(1798, 9)\n",
      "(1591, 9)\n"
     ]
    }
   ],
   "source": [
    "#We now see a significant amount of the data in the new data set is repeated entries and possibly spurious.\n",
    "#More tests should be run. First We drop all duplicate emails.\n",
    "\n",
    "df_new_data_q2_no_dupe = df_new_data_q2.drop_duplicates(subset = ['EMail'])\n",
    "\n",
    "print(df_new_data_q2_no_dupe.shape)\n",
    "\n",
    "\n",
    "#It is also seen that the city of Hazlet is included in the cities. Hazlet has a different zip code 07730.\n",
    "#We drop rows from Hazlet.\n",
    "\n",
    "df_new_data_q2_no_dupe = df_new_data_q2_no_dupe[df_new_data_q2_no_dupe.City != 'HAZLET TOWNSHIP']\n",
    "\n",
    "print(df_new_data_q2_no_dupe.shape)\n",
    "\n",
    "#As a final test we will see if any phone numbers are also repeated.\n",
    "\n",
    "df_new_data_q2_no_dupe_final = df_new_data_q2_no_dupe.drop_duplicates(subset = ['Phone Number'])\n",
    "\n",
    "print(df_new_data_q2_no_dupe_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen the original data set for purchase is largely composed of incorrect or repeated values in fields that should\n",
    "#be unique such as phone number and email.\n",
    "#Further cleaning of this set is possible however it is not necessary as the data is poor or more likely fake.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
